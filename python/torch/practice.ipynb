{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33dd4db4-0c53-46a7-bb4e-45e697180331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5516360-db01-4f22-a1d0-decdd6d7350b",
   "metadata": {},
   "source": [
    "# Python basic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4512a8e3-9219-495e-98c9-49dec44a659d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## numpy.repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a6ff6e55-f224-4d56-b3cf-3799c88303d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m= [[[[1.61 0.68 0.06]\n",
      "   [1.53 0.2  0.54]]]], (1, 1, 2, 3)\n",
      "m2= [[[[1.61 0.68 0.06]\n",
      "   [1.53 0.2  0.54]]\n",
      "\n",
      "  [[1.61 0.68 0.06]\n",
      "   [1.53 0.2  0.54]]\n",
      "\n",
      "  [[1.61 0.68 0.06]\n",
      "   [1.53 0.2  0.54]]]\n",
      "\n",
      "\n",
      " [[[1.61 0.68 0.06]\n",
      "   [1.53 0.2  0.54]]\n",
      "\n",
      "  [[1.61 0.68 0.06]\n",
      "   [1.53 0.2  0.54]]\n",
      "\n",
      "  [[1.61 0.68 0.06]\n",
      "   [1.53 0.2  0.54]]]], (2, 3, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "m= np.round(np.random.uniform(0,2,size=(1,1,2,3)), 2)\n",
    "m2= np.repeat(np.repeat(m,3,axis=1),2,axis=0)\n",
    "print(f'm= {m}, {m.shape}')\n",
    "print(f'm2= {m2}, {m2.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e9fa75-0f78-4bd3-a552-074b9b8d4645",
   "metadata": {
    "tags": []
   },
   "source": [
    "## numpy.argsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5510eb0-3db4-41b4-a83a-2ea3f1d32bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a= [9.  2.1 6.4 3.6 6.9 0.7 2.1 9.3 0.5 1.5]\n",
      "sorted indexes: [8 5 9 1 6 3 2 4 0 7]\n",
      "        values: [0.5 0.7 1.5 2.1 2.1 3.6 6.4 6.9 9.  9.3]\n",
      "sorted indexes (rev): [7 0 4 2 3 6 1 9 5 8]\n",
      "              values: [9.3 9.  6.9 6.4 3.6 2.1 2.1 1.5 0.7 0.5]\n"
     ]
    }
   ],
   "source": [
    "a= np.round(np.random.uniform(0,10,size=10),1)\n",
    "print(f'a= {a}')\n",
    "print(f'sorted indexes: {np.argsort(a)}')\n",
    "print(f'        values: {a[np.argsort(a)]}')\n",
    "print(f'sorted indexes (rev): {np.argsort(a)[::-1]}')\n",
    "print(f'              values: {a[np.argsort(a)[::-1]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e74dfcc-d1d2-409d-a3d4-d3ef44575dbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## numpy.argpartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3e784b9-7ec1-4a91-b2f1-c9aa78d97a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a= [3.3 4.2 3.3 7.5 5.1 7.6 4.  6.8 1.  0.8]\n",
      "lowest 3 indexes: [8 9 0]\n",
      "          values: [1.  0.8 3.3]\n",
      "  sorted indexes: [9 8 0]\n",
      "          values: [0.8 1.  3.3]\n",
      "   other indexes: [2 6 1 4 7 5 3]\n",
      "          values: [3.3 4.  4.2 5.1 6.8 7.6 7.5]\n",
      "highest 3 indexes: [7 3 5]\n",
      "           values: [6.8 7.5 7.6]\n",
      "   sorted indexes: [5 3 7]\n",
      "           values: [7.6 7.5 6.8]\n",
      "    other indexes: [8 9 0 1 6 2 4]\n",
      "           values: [1.  0.8 3.3 4.2 4.  3.3 5.1]\n"
     ]
    }
   ],
   "source": [
    "a= np.round(np.random.uniform(0,10,size=10),1)\n",
    "def argsort_N(a, N, reverse=False):\n",
    "  if not reverse:\n",
    "    idxes= np.argpartition(a,N)[:N]\n",
    "    return idxes[np.argsort(a[idxes])]\n",
    "  else:\n",
    "    idxes= np.argpartition(a,-N)[-N:]\n",
    "    return idxes[np.argsort(a[idxes])[::-1]]\n",
    "print(f'a= {a}')\n",
    "print(f'lowest 3 indexes: {np.argpartition(a,3)[:3]}')\n",
    "print(f'          values: {a[np.argpartition(a,3)[:3]]}')\n",
    "print(f'  sorted indexes: {argsort_N(a,3)}')\n",
    "print(f'          values: {a[argsort_N(a,3)]}')\n",
    "print(f'   other indexes: {np.argpartition(a,3)[3:]}')\n",
    "print(f'          values: {a[np.argpartition(a,3)[3:]]}')\n",
    "\n",
    "print(f'highest 3 indexes: {np.argpartition(a,-3)[-3:]}')\n",
    "print(f'           values: {a[np.argpartition(a,-3)[-3:]]}')\n",
    "print(f'   sorted indexes: {argsort_N(a,3,reverse=True)}')\n",
    "print(f'           values: {a[argsort_N(a,3,reverse=True)]}')\n",
    "print(f'    other indexes: {np.argpartition(a,-3)[:-3]}')\n",
    "print(f'           values: {a[np.argpartition(a,-3)[:-3]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf00ec9-ad30-48fe-9e52-7fafbd7302d6",
   "metadata": {},
   "source": [
    "## Broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f345b302-74b4-49eb-bd76-4d348e9576b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A= [[1.  0.1 0.4 0.4]\n",
      " [0.1 0.5 0.7 0. ]\n",
      " [0.2 0.7 0.1 1. ]]\n",
      "B= [[0.4 0.1 0.7]\n",
      " [0.4 0.4 0.3]\n",
      " [0.6 0.3 0. ]\n",
      " [0.2 0.6 1. ]]\n",
      "c= [2. 1. 1.]\n",
      "A@B= [[0.76 0.5  1.13]\n",
      " [0.66 0.42 0.22]\n",
      " [0.62 0.93 1.35]]\n",
      "A@B+c= [[2.76 1.5  2.13]\n",
      " [2.66 1.42 1.22]\n",
      " [2.62 1.93 2.35]]\n",
      "A@B+c.reshape((3,1))= [[2.76 2.5  3.13]\n",
      " [1.66 1.42 1.22]\n",
      " [1.62 1.93 2.35]]\n"
     ]
    }
   ],
   "source": [
    "A= np.round(np.random.uniform(0,1,size=(3,4)), 1)\n",
    "B= np.round(np.random.uniform(0,1,size=(4,3)), 1)\n",
    "c= np.round(np.random.uniform(0,3,size=(3,)), 0)\n",
    "print(f'A= {A}')\n",
    "print(f'B= {B}')\n",
    "print(f'c= {c}')\n",
    "print(f'A@B= {A@B}')\n",
    "print(f'A@B+c= {A@B+c}')\n",
    "print(f'A@B+c.reshape((3,1))= {A@B+c.reshape((3,1))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad2afec-007d-4bb2-b5e4-25726c4bf03c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d800198f-3997-4279-b96e-f94c288ad053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A= [[0.27 1.72 0.99 0.78]\n",
      " [0.4  0.43 1.34 1.19]\n",
      " [0.12 0.28 0.34 1.68]]\n",
      "B= [[-0.23  0.74 -0.15]\n",
      " [ 0.64  0.07  0.46]\n",
      " [-0.79 -0.24  0.18]\n",
      " [-0.09  0.45  0.53]]\n",
      "A@B= [[ 0.1864  0.4336  1.3423]\n",
      " [-0.9825  0.54    1.0097]\n",
      " [-0.2682  0.7828  1.0624]]\n",
      "ik,kj->ij= [[ 0.1864  0.4336  1.3423]\n",
      " [-0.9825  0.54    1.0097]\n",
      " [-0.2682  0.7828  1.0624]]\n",
      "A*(B.T)= [[-0.0621  1.1008 -0.7821 -0.0702]\n",
      " [ 0.296   0.0301 -0.3216  0.5355]\n",
      " [-0.018   0.1288  0.0612  0.8904]]\n",
      "ij,ji->ij= [[-0.0621  1.1008 -0.7821 -0.0702]\n",
      " [ 0.296   0.0301 -0.3216  0.5355]\n",
      " [-0.018   0.1288  0.0612  0.8904]]\n"
     ]
    }
   ],
   "source": [
    "A= np.round(np.random.uniform(0,2,size=(3,4)), 2)\n",
    "B= np.round(np.random.uniform(-1,1,size=(4,3)), 2)\n",
    "print(f'A= {A}')\n",
    "print(f'B= {B}')\n",
    "print(f'A@B= {A@B}')\n",
    "print(f\"ik,kj->ij= {np.einsum('ik,kj->ij',A,B)}\")\n",
    "print(f'A*(B.T)= {A*(B.T)}')\n",
    "print(f\"ij,ji->ij= {np.einsum('ij,ji->ij',A,B)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1839e841-92b1-4af3-98aa-02627e667fe3",
   "metadata": {},
   "source": [
    "## Container class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afd17d15-71e0-4525-8fb3-1b02d9541523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Local variable holder.\n",
    "class TLocalVar:\n",
    "  def __init__(self, l):\n",
    "    self.__dict__= l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd1d5477-0261-4e63-9bcc-bd7f4b6d77b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b': 10, 'a': 100}\n",
      "<__main__.TLocalVar object at 0x7fe432f197b8>\n",
      "100 10\n",
      "10000 1000\n",
      "100 10\n",
      "100 10\n"
     ]
    }
   ],
   "source": [
    "def test_f(a):\n",
    "  b= 10\n",
    "  print(locals())\n",
    "  l= TLocalVar(locals())\n",
    "  print(l)\n",
    "  # print(l['a'])\n",
    "  print(l.a,l.b)\n",
    "  l.a*= 100\n",
    "  l.b*= 100\n",
    "  print(l.a,l.b)\n",
    "  print(a,b)\n",
    "  locals()['a']*= 100\n",
    "  print(a,b)\n",
    "test_f(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63f4cb81-ee08-4395-ad5b-1bcaf5ad7613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Container class to share variables.\n",
    "class TContainer(object):\n",
    "  def __init__(self):\n",
    "    pass\n",
    "  def __del__(self):\n",
    "    pass\n",
    "  def __str__(self):\n",
    "    return str(self.__dict__)\n",
    "  def __repr__(self):\n",
    "    return str(self.__dict__)\n",
    "  def __iter__(self):\n",
    "    return self.__dict__.itervalues()\n",
    "  def items(self):\n",
    "    return self.__dict__.items()\n",
    "  def iteritems(self):\n",
    "    return self.__dict__.iteritems()\n",
    "  def keys(self):\n",
    "    return self.__dict__.keys()\n",
    "  def values(self):\n",
    "    return self.__dict__.values()\n",
    "  def __getitem__(self,key):\n",
    "    return self.__dict__[key]\n",
    "  def __setitem__(self,key,value):\n",
    "    self.__dict__[key]= value\n",
    "  def __delitem__(self,key):\n",
    "    del self.__dict__[key]\n",
    "  def __contains__(self,key):\n",
    "    return key in self.__dict__\n",
    "  def Cleanup(self):\n",
    "    keys= self.__dict__.keys()\n",
    "    for k in keys:\n",
    "      self.__dict__[k]= None\n",
    "      del self.__dict__[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0676f7cd-3474-4529-a64b-1265cdc7d125",
   "metadata": {},
   "outputs": [],
   "source": [
    "l= TContainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76635cb3-5d93-45b1-8fde-b4f225ec8aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for l.i in range(3):\n",
    "  print(l.i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe63e554-3174-4541-a70a-2eb06e562d5e",
   "metadata": {},
   "source": [
    "## Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89518ed4-2d97-42cb-95fd-2cfac6be933a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disc.NumClasses()= 12\n",
      "X= [-3.0, -2.2222222222222223, -1.4444444444444444, -0.6666666666666665, 0.11111111111111116, 0.8888888888888888, 1.666666666666667, 2.4444444444444446, 3.2222222222222223, 4.0]\n",
      "disc.Encode(x)= [0.0, 0.0, 2.0, 3.0, 5.0, 6.0, 8.0, 9.0, 11.0, 11.0]\n",
      "disc.Encode(np.array(X))= [ 0.  0.  2.  3.  5.  6.  8.  9. 11. 11.]\n",
      "disc.Encode(torch.tensor(X).float())= tensor([ 0,  0,  2,  3,  5,  6,  8,  9, 11, 11])\n",
      "C= [10  9 -1 11 10  6  4  6  0 -1]\n",
      "disc.Decode(c)= [2.75, 2.25, -2.25, 3.25, 2.75, 0.75, -0.25, 0.75, -2.25, -2.25]\n",
      "disc.Decode(np.array(C))= [ 2.75  2.25 -2.25  3.25  2.75  0.75 -0.25  0.75 -2.25 -2.25]\n",
      "disc.Decode(torch.tensor(C))= tensor([ 2.7500,  2.2500, -2.2500,  3.2500,  2.7500,  0.7500, -0.2500,  0.7500,\n",
      "        -2.2500, -2.2500])\n"
     ]
    }
   ],
   "source": [
    "class TDiscretizer(object):\n",
    "  def __init__(self, xmin, xmax, n_div):\n",
    "    self.xmin, self.xmax, self.n_div= xmin, xmax, n_div\n",
    "    self.dx= (xmax-xmin)/n_div\n",
    "    self.ptcls_max= torch.tensor(self.n_div-1)\n",
    "    self.ptcls_min= torch.tensor(0)\n",
    "  def NumClasses(self):  return self.n_div\n",
    "  def Encode(self, x):  \n",
    "    if isinstance(x,torch.Tensor):\n",
    "      return torch.minimum(self.ptcls_max,torch.maximum(self.ptcls_min,torch.floor((x-self.xmin)/self.dx))).long()\n",
    "    return np.minimum(self.n_div-1,np.maximum(0,np.floor((x-self.xmin)/self.dx)))\n",
    "  def Decode(self, c):\n",
    "    if isinstance(c, torch.Tensor):\n",
    "      return (self.xmin+0.5*self.dx)+self.dx*torch.minimum(self.ptcls_max,torch.maximum(self.ptcls_min,c))\n",
    "    return (self.xmin+0.5*self.dx)+self.dx*np.minimum(self.n_div-1,np.maximum(0,c))\n",
    "disc= TDiscretizer(-2.5, 3.5, 12)\n",
    "print(f'disc.NumClasses()= {disc.NumClasses()}')\n",
    "# np.minimum(3,np.array(range(10))), np.minimum(3,0)\n",
    "# torch.minimum(torch.tensor(3),torch.tensor(range(10))), torch.minimum(3,0)\n",
    "# torch.tensor(range(10))-4\n",
    "X= [x for x in np.linspace(-3.,4.,10)]\n",
    "print(f'X= {X}')\n",
    "print(f'disc.Encode(x)= {[disc.Encode(x) for x in X]}')\n",
    "print(f'disc.Encode(np.array(X))= {disc.Encode(np.array(X))}')\n",
    "print(f'disc.Encode(torch.tensor(X).float())= {disc.Encode(torch.tensor(X).float())}')\n",
    "C= np.random.randint(-1,15, size=(10))\n",
    "print(f'C= {C}')\n",
    "print(f'disc.Decode(c)= {[disc.Decode(c) for c in C]}')\n",
    "print(f'disc.Decode(np.array(C))= {disc.Decode(np.array(C))}')\n",
    "print(f'disc.Decode(torch.tensor(C))= {disc.Decode(torch.tensor(C))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2997f12-cea9-4df4-a22c-e85f0ab69a21",
   "metadata": {},
   "source": [
    "# Torch Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ef204c-076b-45bc-bbb5-b2f38dae470f",
   "metadata": {},
   "source": [
    "## shape and view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c4e2384-ccf9-4aee-9ae5-0d24c703e259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_batch= 1\n",
    "n_batch= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4003e627-2780-4b45-9540-ca1a80a21370",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= torch.tensor(np.zeros((n_batch,3,32,32))).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1adcd99c-66bb-457d-b631-8469cbea5189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 32, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "143ea2e8-2fc6-4de0-a432-07604bbb315f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cefe48b-bcfb-498f-98e2-3df3d8ab8e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3072])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(x.size(0), -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b63fd7e-d3ea-4611-b5b4-934fb1d2395c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=3072, out_features=10, bias=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=torch.nn.Linear(x[0].numel(), 10)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfbf94ba-e349-4e99-a8e2-203fb46672ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0170, -0.0096, -0.0093, -0.0021,  0.0015,  0.0124,  0.0121,  0.0003,\n",
       "        -0.0003, -0.0002], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l(x[0].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a42f4b3-532d-433a-9459-fd3c529657ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0170, -0.0096, -0.0093, -0.0021,  0.0015,  0.0124,  0.0121,  0.0003,\n",
       "         -0.0003, -0.0002],\n",
       "        [ 0.0170, -0.0096, -0.0093, -0.0021,  0.0015,  0.0124,  0.0121,  0.0003,\n",
       "         -0.0003, -0.0002],\n",
       "        [ 0.0170, -0.0096, -0.0093, -0.0021,  0.0015,  0.0124,  0.0121,  0.0003,\n",
       "         -0.0003, -0.0002],\n",
       "        [ 0.0170, -0.0096, -0.0093, -0.0021,  0.0015,  0.0124,  0.0121,  0.0003,\n",
       "         -0.0003, -0.0002]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ebb019-610e-4640-b9dc-2c352ae9f0da",
   "metadata": {},
   "source": [
    "## cat (concatenate) and stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e80ca54-f1f4-4296-917f-4c4b20f641b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1=tensor([2., 3., 4.])\n",
      "x2=tensor([10., 22., 12.])\n",
      "torch.cat=tensor([ 2.,  3.,  4., 10., 22., 12.])\n",
      "torch.stack=tensor([[ 2.,  3.,  4.],\n",
      "        [10., 22., 12.]])\n"
     ]
    }
   ],
   "source": [
    "x1= torch.from_numpy(np.array([2,3,4])).float()\n",
    "x2= torch.from_numpy(np.array([10,22,12])).float()\n",
    "print(f'x1={x1}')\n",
    "print(f'x2={x2}')\n",
    "print(f'torch.cat={torch.cat((x1,x2),axis=0)}')\n",
    "print(f'torch.stack={torch.stack((x1,x2),axis=0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec1324f-4709-4b08-866d-fffb0765b492",
   "metadata": {},
   "source": [
    "## view and flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "377877c4-c347-4b59-9914-115cfdcba967",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batch= 64\n",
    "x= torch.tensor(np.zeros((n_batch,128,6,6))).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9e00c52b-8e48-457a-9669-36392a9a5e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 128, 6, 6])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e8c888bc-8e08-42a5-9350-d85c4400cf24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4608])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(x.shape[0], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c265d07a-5ee8-462c-a44a-e911139a30b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4608])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten= torch.nn.Flatten()\n",
    "flatten(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "42c38211-201f-4dc8-879f-54f42e6bf658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4608])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(x,1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf474f6-f5be-4e8b-8ce3-cdc939170357",
   "metadata": {},
   "source": [
    "## unflatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "de07d021-d754-4c29-8132-719fa03abd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 128, 6, 6])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Unflatten(1,(128,6,6))(torch.flatten(x,1)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf95f24a-6364-49df-9ed2-7099f5acfba1",
   "metadata": {},
   "source": [
    "## Unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4dd77471-dcf8-419b-b58c-96b9bc207039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 10, 10]), torch.Size([1, 3, 10, 10]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= torch.zeros(3,10,10)\n",
    "x.shape, x.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1cfa63-7758-474f-b7da-06748cb2e50d",
   "metadata": {},
   "source": [
    "# Torch Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dfe6d8-7201-420d-a1d9-965a971f97b1",
   "metadata": {},
   "source": [
    "## Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ef46634-bb1e-4ab8-89d8-ec0f13dc62b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1=Sequential(\n",
      "  (0): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (1): Linear(in_features=3, out_features=4, bias=True)\n",
      ")\n",
      "l2=Sequential(\n",
      "  (0): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (1): None\n",
      "  (2): Linear(in_features=3, out_features=4, bias=True)\n",
      ")\n",
      "l2b=Sequential(\n",
      "  (0): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (1): TNoop()\n",
      "  (2): Linear(in_features=3, out_features=4, bias=True)\n",
      ")\n",
      "l3=Sequential(\n",
      "  (0): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (1): Linear(in_features=3, out_features=4, bias=True)\n",
      ")\n",
      "x=tensor([1., 1., 1.])\n",
      "l1(x)=tensor([-0.2396,  0.3478, -0.1649, -0.6443], grad_fn=<AddBackward0>)\n",
      "l2b(x)=tensor([ 0.1232, -0.1427, -0.7143,  0.4091], grad_fn=<AddBackward0>)\n",
      "l3(x)=tensor([-0.1548, -0.1635,  0.3904, -0.3709], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from ay_torch import Noop, TNoop\n",
    "# print(isinstance(TNoop(),torch.nn.Module))\n",
    "x= torch.ones(3)\n",
    "l1= torch.nn.Sequential(torch.nn.Linear(3,3),torch.nn.Linear(3,4))\n",
    "l2= torch.nn.Sequential(torch.nn.Linear(3,3),None,torch.nn.Linear(3,4))\n",
    "l2b= torch.nn.Sequential(torch.nn.Linear(3,3),TNoop(),torch.nn.Linear(3,4))\n",
    "l3= torch.nn.Sequential(*filter(lambda x:x is not None, (torch.nn.Linear(3,3),None,torch.nn.Linear(3,4))))\n",
    "print(f'l1={l1}')\n",
    "print(f'l2={l2}')\n",
    "print(f'l2b={l2b}')\n",
    "print(f'l3={l3}')\n",
    "print(f'x={x}')\n",
    "print(f'l1(x)={l1(x)}')\n",
    "# print(f'l2(x)={l2(x)}')  #ERROR: TypeError: 'NoneType' object is not callable\n",
    "print(f'l2b(x)={l2b(x)}')\n",
    "print(f'l3(x)={l3(x)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1f62ef3-d430-4007-8c16-58f109f898de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l4=Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=3, bias=True)\n",
      "    (1): Linear(in_features=3, out_features=4, bias=True)\n",
      "  )\n",
      "  (1): Linear(in_features=4, out_features=3, bias=True)\n",
      ")\n",
      "l4(x)=tensor([0.4532, 0.0684, 0.5474], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# l3.append(torch.nn.Linear(4,3))  #AttributeError: 'Sequential' object has no attribute 'append'\n",
    "l4= torch.nn.Sequential(l3, torch.nn.Linear(4,3))\n",
    "print(f'l4={l4}')\n",
    "print(f'l4(x)={l4(x)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e08707-6d53-470c-b050-c5f7162278e8",
   "metadata": {},
   "source": [
    "## BatchNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ca62433d-3c13-4617-8341-d337aa4dc4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x= tensor([[7.5000, 8.0000, 3.5000, 2.0000, 8.5000],\n",
      "        [9.0000, 5.0000, 4.0000, 6.5000, 1.0000],\n",
      "        [9.5000, 5.5000, 3.0000, 1.5000, 0.5000],\n",
      "        [7.0000, 0.0000, 6.0000, 4.5000, 2.5000]]) (shape=torch.Size([4, 5]))\n",
      "bn(x)= tensor([[-0.7276,  1.1630, -0.5488, -0.8078,  1.6853],\n",
      "        [ 0.7276,  0.1292, -0.1098,  1.4291, -0.6663],\n",
      "        [ 1.2127,  0.3015, -0.9879, -1.0563, -0.8231],\n",
      "        [-1.2127, -1.5937,  1.6465,  0.4350, -0.1960]],\n",
      "       grad_fn=<NativeBatchNormBackward>)\n"
     ]
    }
   ],
   "source": [
    "x= torch.tensor(range(20))/2.0\n",
    "x= x[torch.randperm(x.shape[0])].reshape(-1,5)\n",
    "print(f'x= {x} (shape={x.shape})')\n",
    "bn= torch.nn.BatchNorm1d(5)\n",
    "# bn.bias.data.fill_(1e-3)\n",
    "bn.weight.data.fill_(0.)\n",
    "# bn.bias.data= torch.Tensor([1.,2.,3.,4.,5.])*0.1\n",
    "# bn.weight.data= torch.Tensor([5.,4.,3.,2.,1.])*0.1\n",
    "bn.weight.data.fill_(1.)\n",
    "print(f'bn(x)= {bn(x)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4329175b-4f29-4d94-8337-112e84820da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1.]), tensor([0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn.weight.data, bn.bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3f9ce4b5-6e62-4ce2-aeb8-55608e98b81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6301,  1.0072, -0.4753, -0.6996,  1.4595],\n",
       "        [ 0.6301,  0.1119, -0.0951,  1.2377, -0.5770],\n",
       "        [ 1.0502,  0.2611, -0.8555, -0.9148, -0.7128],\n",
       "        [-1.0502, -1.3802,  1.4259,  0.3767, -0.1697]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(x,axis=0), torch.var(x,axis=0)\n",
    "(x-torch.mean(x,axis=0))/torch.sqrt(torch.var(x,axis=0)) * bn.weight + bn.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ddcda507-9171-4748-8aa8-2e1f308501e3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "InstanceNorm1d returns 0-filled tensor to 2D tensor.This is because InstanceNorm1d reshapes inputs to(1, N * C, ...) from (N, C,...) and this makesvariances 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-914f3ccaff3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# inn.weight.data= torch.Tensor([5.,4.,3.,2.,1.])*0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# inn.weight.data.fill_(1.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'inn(x)= {inn(x)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/instancenorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_input_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         return F.instance_norm(\n\u001b[1;32m     58\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/instancenorm.py\u001b[0m in \u001b[0;36m_check_input_dim\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             raise ValueError(\n\u001b[0;32m--> 133\u001b[0;31m                 \u001b[0;34m'InstanceNorm1d returns 0-filled tensor to 2D tensor.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m                 \u001b[0;34m'This is because InstanceNorm1d reshapes inputs to'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0;34m'(1, N * C, ...) from (N, C,...) and this makes'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: InstanceNorm1d returns 0-filled tensor to 2D tensor.This is because InstanceNorm1d reshapes inputs to(1, N * C, ...) from (N, C,...) and this makesvariances 0."
     ]
    }
   ],
   "source": [
    "inn= torch.nn.InstanceNorm1d(5, affine=True)\n",
    "# inn.bias.data.fill_(1e-3)\n",
    "# inn.weight.data.fill_(0.)\n",
    "# inn.bias.data= torch.Tensor([1.,2.,3.,4.,5.])*0.1\n",
    "# inn.weight.data= torch.Tensor([5.,4.,3.,2.,1.])*0.1\n",
    "# inn.weight.data.fill_(1.)\n",
    "print(f'inn(x)= {inn(x)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1452707-6a61-431a-a5df-bfdfda03ff71",
   "metadata": {},
   "source": [
    "## Max module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c57a4225-f72c-4f3f-abc4-96232d36dd18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[59.0000, 17.0000, 55.5000, 56.5000, 58.5000],\n",
       "          [24.0000, 39.5000, 50.5000, 62.0000, 72.5000],\n",
       "          [28.0000, 42.5000, 41.0000, 51.0000, 36.5000],\n",
       "          [54.0000, 70.0000, 35.5000, 20.0000, 28.5000],\n",
       "          [26.0000, 16.0000,  6.0000, 70.5000, 49.0000]],\n",
       "\n",
       "         [[19.0000,  0.0000, 23.0000, 48.5000, 14.0000],\n",
       "          [65.5000, 36.0000,  4.0000, 64.0000, 12.0000],\n",
       "          [25.0000, 34.0000, 35.0000,  2.5000, 30.5000],\n",
       "          [61.0000, 54.5000, 25.5000, 60.0000, 69.0000],\n",
       "          [65.0000,  1.5000, 68.0000, 45.0000, 32.0000]],\n",
       "\n",
       "         [[19.5000, 31.0000, 57.5000, 13.0000, 46.0000],\n",
       "          [55.0000, 14.5000, 53.5000,  2.0000, 43.5000],\n",
       "          [49.5000, 67.5000, 46.5000, 15.5000, 61.5000],\n",
       "          [34.5000,  3.0000, 10.5000, 44.0000,  1.0000],\n",
       "          [ 9.0000, 38.5000, 60.5000, 33.5000, 72.0000]]],\n",
       "\n",
       "\n",
       "        [[[33.0000, 73.5000, 41.5000,  4.5000, 18.5000],\n",
       "          [31.5000,  3.5000,  5.0000, 63.0000, 62.5000],\n",
       "          [69.5000, 23.5000, 40.5000, 71.5000, 20.5000],\n",
       "          [16.5000, 18.0000, 47.0000, 48.0000, 22.5000],\n",
       "          [29.0000, 74.0000, 74.5000,  9.5000, 27.0000]],\n",
       "\n",
       "         [[29.5000, 63.5000, 67.0000, 17.5000, 66.0000],\n",
       "          [13.5000, 21.0000, 11.0000, 45.5000, 44.5000],\n",
       "          [27.5000, 58.0000, 42.0000,  7.5000, 24.5000],\n",
       "          [ 6.5000, 37.5000, 56.0000,  8.0000, 47.5000],\n",
       "          [40.0000, 50.0000, 73.0000, 53.0000, 52.5000]],\n",
       "\n",
       "         [[68.5000,  8.5000, 52.0000, 26.5000, 43.0000],\n",
       "          [ 0.5000, 51.5000, 57.0000, 66.5000, 22.0000],\n",
       "          [38.0000, 10.0000, 71.0000, 32.5000, 12.5000],\n",
       "          [ 7.0000, 64.5000, 11.5000, 21.5000, 15.0000],\n",
       "          [30.0000, 59.5000, 39.0000, 37.0000,  5.5000]]]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= torch.tensor(range(150))/2.0\n",
    "x= x[torch.randperm(x.shape[0])].reshape(-1,3,5,5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1fbf9b93-dd99-4933-bc1c-e556677ea1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5, 5])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x, axis=1)[0].unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "15923a8d-9903-4a91-a9a5-91b992e4529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TMax(torch.nn.Module):\n",
    "  def forward(self, x):\n",
    "    return torch.max(x, axis=1)[0].unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "720a3575-d763-4eee-b0cc-d7d1ffec8078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[59.0000, 31.0000, 57.5000, 56.5000, 58.5000],\n",
       "          [65.5000, 39.5000, 53.5000, 64.0000, 72.5000],\n",
       "          [49.5000, 67.5000, 46.5000, 51.0000, 61.5000],\n",
       "          [61.0000, 70.0000, 35.5000, 60.0000, 69.0000],\n",
       "          [65.0000, 38.5000, 68.0000, 70.5000, 72.0000]]],\n",
       "\n",
       "\n",
       "        [[[68.5000, 73.5000, 67.0000, 26.5000, 66.0000],\n",
       "          [31.5000, 51.5000, 57.0000, 66.5000, 62.5000],\n",
       "          [69.5000, 58.0000, 71.0000, 71.5000, 24.5000],\n",
       "          [16.5000, 64.5000, 56.0000, 48.0000, 47.5000],\n",
       "          [40.0000, 74.0000, 74.5000, 53.0000, 52.5000]]]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m= TMax()\n",
    "m(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d47600a-8c7c-49c8-b949-c9c3cc7f9dc4",
   "metadata": {},
   "source": [
    "## AvgPool2d and Upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d13bb2ee-dfd8-4bcf-b704-c6f9848099d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 8, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.2388, 0.1915, 0.6603, 0.9222, 0.2945, 0.0357, 0.7832, 0.1920],\n",
       "          [0.4177, 0.8654, 0.8985, 0.7739, 0.7018, 0.4917, 0.0838, 0.7546],\n",
       "          [0.2234, 0.6977, 0.2054, 0.9994, 0.8951, 0.7883, 0.3776, 0.6775],\n",
       "          [0.4321, 0.6387, 0.0568, 0.0692, 0.7113, 0.3858, 0.5290, 0.1512],\n",
       "          [0.7873, 0.7903, 0.5976, 0.1046, 0.5114, 0.9380, 0.3291, 0.2403],\n",
       "          [0.2715, 0.7936, 0.8609, 0.6254, 0.4417, 0.2772, 0.4428, 0.8376],\n",
       "          [0.5523, 0.5319, 0.9425, 0.3161, 0.6561, 0.8714, 0.4156, 0.9550],\n",
       "          [0.4729, 0.7059, 0.4009, 0.0883, 0.2010, 0.8251, 0.3593, 0.3616]]]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img= torch.from_numpy(np.random.uniform(0,1,size=(1,1,8,8))).float()\n",
    "print(img.shape)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f2bfcd8a-9c5e-4c33-93f3-371bc18f58e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.4283, 0.8137, 0.3809, 0.4534],\n",
       "          [0.4980, 0.3327, 0.6951, 0.4338],\n",
       "          [0.6607, 0.5471, 0.5421, 0.4624],\n",
       "          [0.5658, 0.4369, 0.6384, 0.5228]]]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2= torch.nn.AvgPool2d(kernel_size=2, stride=None, padding=0, ceil_mode=True)(img)\n",
    "print(img2.shape)\n",
    "img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bb007e21-49a5-4cd6-af3e-496a23b556d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 8, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.4283, 0.4283, 0.8137, 0.8137, 0.3809, 0.3809, 0.4534, 0.4534],\n",
       "          [0.4283, 0.4283, 0.8137, 0.8137, 0.3809, 0.3809, 0.4534, 0.4534],\n",
       "          [0.4980, 0.4980, 0.3327, 0.3327, 0.6951, 0.6951, 0.4338, 0.4338],\n",
       "          [0.4980, 0.4980, 0.3327, 0.3327, 0.6951, 0.6951, 0.4338, 0.4338],\n",
       "          [0.6607, 0.6607, 0.5471, 0.5471, 0.5421, 0.5421, 0.4624, 0.4624],\n",
       "          [0.6607, 0.6607, 0.5471, 0.5471, 0.5421, 0.5421, 0.4624, 0.4624],\n",
       "          [0.5658, 0.5658, 0.4369, 0.4369, 0.6384, 0.6384, 0.5228, 0.5228],\n",
       "          [0.5658, 0.5658, 0.4369, 0.4369, 0.6384, 0.6384, 0.5228, 0.5228]]]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img3= torch.nn.Upsample(scale_factor=2, mode='nearest', align_corners=None)(img2)\n",
    "print(img3.shape)\n",
    "img3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0872f2e3-dc97-47fc-91b6-716ede87b32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 10, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.4283, 0.4283, 0.4283, 0.8137, 0.8137, 0.3809, 0.3809, 0.3809,\n",
       "           0.4534, 0.4534],\n",
       "          [0.4283, 0.4283, 0.4283, 0.8137, 0.8137, 0.3809, 0.3809, 0.3809,\n",
       "           0.4534, 0.4534],\n",
       "          [0.4283, 0.4283, 0.4283, 0.8137, 0.8137, 0.3809, 0.3809, 0.3809,\n",
       "           0.4534, 0.4534],\n",
       "          [0.4980, 0.4980, 0.4980, 0.3327, 0.3327, 0.6951, 0.6951, 0.6951,\n",
       "           0.4338, 0.4338],\n",
       "          [0.4980, 0.4980, 0.4980, 0.3327, 0.3327, 0.6951, 0.6951, 0.6951,\n",
       "           0.4338, 0.4338],\n",
       "          [0.6607, 0.6607, 0.6607, 0.5471, 0.5471, 0.5421, 0.5421, 0.5421,\n",
       "           0.4624, 0.4624],\n",
       "          [0.6607, 0.6607, 0.6607, 0.5471, 0.5471, 0.5421, 0.5421, 0.5421,\n",
       "           0.4624, 0.4624],\n",
       "          [0.6607, 0.6607, 0.6607, 0.5471, 0.5471, 0.5421, 0.5421, 0.5421,\n",
       "           0.4624, 0.4624],\n",
       "          [0.5658, 0.5658, 0.5658, 0.4369, 0.4369, 0.6384, 0.6384, 0.6384,\n",
       "           0.5228, 0.5228],\n",
       "          [0.5658, 0.5658, 0.5658, 0.4369, 0.4369, 0.6384, 0.6384, 0.6384,\n",
       "           0.5228, 0.5228]]]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img4= torch.nn.Upsample(size=(10,10), mode='nearest', align_corners=None)(img2)\n",
    "print(img4.shape)\n",
    "img4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e5c705-9340-4532-a589-cb516dbe9787",
   "metadata": {},
   "source": [
    "## Unfold+bmm and Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e4a9d28-99e4-4c39-9f8a-21e9d6712815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img= torch.from_numpy(np.random.uniform(0,1,size=(1,1,4,4))).float()\n",
    "img= torch.tensor(range(16)).float().reshape(1,1,4,4)\n",
    "print(img.shape)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43145320-5081-4901-822f-28b905356ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: []\n",
      "torch.Size([1, 4, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.,  4.,  5.,  6.,  8.,  9., 10.],\n",
       "         [ 1.,  2.,  3.,  5.,  6.,  7.,  9., 10., 11.],\n",
       "         [ 4.,  5.,  6.,  8.,  9., 10., 12., 13., 14.],\n",
       "         [ 5.,  6.,  7.,  9., 10., 11., 13., 14., 15.]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfold= torch.nn.Unfold(kernel_size=(2,2))\n",
    "print(f'parameters: {[p for p in unfold.parameters()]}')\n",
    "img_u= unfold(img)\n",
    "print(img_u.shape)\n",
    "img_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a793cf43-2e57-48c1-ae51-8630596acb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight: tensor([[[[-0.4410, -0.1046],\n",
      "          [ 0.4316,  0.4210]]]])\n",
      "unfold(weight): tensor([[[-0.4410],\n",
      "         [-0.1046],\n",
      "         [ 0.4316],\n",
      "         [ 0.4210]]]), torch.Size([1, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "conv= torch.nn.Conv2d(in_channels=1,out_channels=1,kernel_size=(2,2),bias=False)\n",
    "print(f'weight: {conv.weight.data}')\n",
    "print(f'unfold(weight): {unfold(conv.weight.data)}, {unfold(conv.weight.data).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a7e340a9-b460-47cd-9560-57f5f691eeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv(img): tensor([[[[3.7269, 4.0339, 4.3409],\n",
      "          [4.9549, 5.2619, 5.5690],\n",
      "          [6.1830, 6.4900, 6.7970]]]], grad_fn=<ThnnConv2DBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[3.7269, 4.0339, 4.3409],\n",
       "          [4.9549, 5.2619, 5.5690],\n",
       "          [6.1830, 6.4900, 6.7970]]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'conv(img): {conv(img)}')\n",
    "torch.bmm(img_u.transpose(2,1), unfold(conv.weight.data)).view(-1,1,3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd52ede4-ee05-45a5-8f19-960b92c2a65d",
   "metadata": {},
   "source": [
    "## Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "301132ee-7be9-49ad-b9a2-754fca389097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ay_torch import ConvLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6350e53c-623f-4c02-a5d2-16da3456dde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.2839, 0.8808, 0.0139, 0.8287, 0.5301, 0.6634, 0.6912, 0.9814],\n",
       "          [0.1733, 0.3598, 0.4103, 0.4994, 0.0770, 0.8473, 0.9285, 0.0275],\n",
       "          [0.3501, 0.0781, 0.8500, 0.1458, 0.3770, 0.5725, 0.0959, 0.7596],\n",
       "          [0.3627, 0.7821, 0.7763, 0.7251, 0.4945, 0.2048, 0.5201, 0.4572],\n",
       "          [0.2111, 0.1763, 0.3066, 0.7494, 0.9515, 0.7900, 0.2000, 0.5780],\n",
       "          [0.3230, 0.6924, 0.6222, 0.3055, 0.3279, 0.3511, 0.2773, 0.9002],\n",
       "          [0.1326, 0.8908, 0.0514, 0.3623, 0.6731, 0.9318, 0.0854, 0.5532],\n",
       "          [0.4673, 0.3573, 0.9547, 0.6804, 0.6719, 0.8438, 0.7647, 0.1715]]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img= torch.from_numpy(np.random.uniform(0,1,size=(1,1,8,8))).float()\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e7b1da3-581f-49d9-94bb-3c5d7567e0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.0390, 0.8798, 0.0000, 0.1952, 1.0140, 0.0000, 0.0000, 1.3001],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.1778, 1.4182],\n",
      "          [0.4135, 0.0000, 0.0000, 0.1114, 0.0000, 0.0000, 1.1794, 0.3791],\n",
      "          [0.0000, 0.5827, 1.8779, 0.4145, 0.0000, 0.0203, 0.0000, 1.8402],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 1.6081, 1.3924, 0.0000, 0.5100],\n",
      "          [0.0000, 0.0000, 0.7051, 0.4953, 0.0000, 0.1407, 0.0000, 1.0345],\n",
      "          [0.0000, 0.0000, 0.0998, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3873, 1.3679, 0.8526, 0.6056, 0.1805, 1.2865, 1.7175, 0.3159]]]],\n",
      "       grad_fn=<ReluBackward1>)\n",
      "torch.Size([1, 1, 8, 8]) torch.Size([1, 3, 8, 8]) torch.Size([1, 1, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "# ConvLayer(1,3,3)(img)\n",
    "# ConvLayer(1,1,3,transpose=True)(img)\n",
    "print(ConvLayer(3,1,3,transpose=True)(ConvLayer(1,3,3)(img)))\n",
    "print(img.shape, ConvLayer(1,3,3)(img).shape, ConvLayer(3,1,3,transpose=True)(ConvLayer(1,3,3)(img)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "544aa322-a9a5-4756-8fa0-d2a83dd1fb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.2139, 0.0000, 0.1058, 0.0000],\n",
      "          [0.3911, 0.0000, 1.5457, 0.0000],\n",
      "          [0.8706, 0.1721, 0.0000, 0.0000],\n",
      "          [1.2724, 0.0000, 0.0813, 0.0000]],\n",
      "\n",
      "         [[0.9741, 0.0000, 1.2964, 0.0000],\n",
      "          [0.6860, 0.2006, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 1.2277, 0.2832],\n",
      "          [0.0000, 0.0000, 1.4465, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.9920, 0.0000, 1.9861],\n",
      "          [0.0000, 0.0000, 0.7416, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9116, 0.0000, 2.2223]]]], grad_fn=<ReluBackward1>)\n",
      "tensor([[[[0.0000, 0.0000, 0.0000, 0.4904, 0.0000, 0.0000, 0.0000, 2.1680],\n",
      "          [0.2877, 0.6108, 0.1776, 0.6291, 0.0000, 4.0315, 0.9366, 3.0488],\n",
      "          [0.2264, 1.2161, 0.3334, 0.0000, 0.0000, 0.0000, 0.0000, 0.0207],\n",
      "          [0.0000, 1.0006, 0.0000, 0.6195, 0.0000, 0.5516, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5167, 0.0000, 0.0000],\n",
      "          [0.0000, 0.3972, 0.0000, 0.0111, 0.0000, 0.0000, 0.0000, 0.3553],\n",
      "          [0.0000, 0.2710, 0.0000, 0.1401, 0.0000, 0.0000, 0.0000, 0.2127],\n",
      "          [0.2280, 0.1566, 0.0000, 0.1399, 0.0000, 1.0671, 0.0000, 0.3526]]]],\n",
      "       grad_fn=<ReluBackward1>)\n",
      "torch.Size([1, 1, 8, 8]) torch.Size([1, 3, 4, 4]) torch.Size([1, 1, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "print(ConvLayer(1,3,3,stride=2)(img))\n",
    "print(ConvLayer(3,1,3,stride=2,transpose=True)(ConvLayer(1,3,3,stride=2)(img)))\n",
    "print(img.shape, ConvLayer(1,3,3,stride=2)(img).shape, ConvLayer(3,1,3,stride=2,transpose=True)(ConvLayer(1,3,3,stride=2)(img)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f9f755-c3be-487b-acd3-f3ddb98b32bf",
   "metadata": {},
   "source": [
    "## ResBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8ff530a5-c164-4f67-b68f-341ae10cb368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ay_torch import TResBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "12791975-ad44-43be-bd47-cfc5b5549265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 8, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "TResBlock                                --                        --\n",
       "Sequential: 1-1                        [1, 3, 8, 8]              --\n",
       "    Sequential: 2-1                   [1, 3, 8, 8]              --\n",
       "        Conv2d: 3-1                  [1, 3, 8, 8]              27\n",
       "        BatchNorm2d: 3-2             [1, 3, 8, 8]              6\n",
       "        ReLU: 3-3                    [1, 3, 8, 8]              --\n",
       "    Sequential: 2-2                   [1, 3, 8, 8]              --\n",
       "        Conv2d: 3-4                  [1, 3, 8, 8]              81\n",
       "        BatchNorm2d: 3-5             [1, 3, 8, 8]              6\n",
       "Sequential: 1-2                        [1, 3, 8, 8]              --\n",
       "    Sequential: 2-3                   [1, 3, 8, 8]              --\n",
       "        Conv2d: 3-6                  [1, 3, 8, 8]              3\n",
       "        BatchNorm2d: 3-7             [1, 3, 8, 8]              6\n",
       "ReLU: 1-3                              [1, 3, 8, 8]              --\n",
       "==========================================================================================\n",
       "Total params: 129\n",
       "Trainable params: 129\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.01\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.01\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.01\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(img.shape)\n",
    "torchinfo.summary(TResBlock(1,1,3),img.shape)\n",
    "# TResBlock(1,1,3)(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "23f02038-15b6-46a3-863c-6d9ab19adeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 8, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "TResBlock                                --                        --\n",
       "Sequential: 1-1                        [1, 1, 8, 8]              --\n",
       "    Sequential: 2-1                   [1, 1, 8, 8]              --\n",
       "        ConvTranspose2d: 3-1         [1, 1, 8, 8]              27\n",
       "        BatchNorm2d: 3-2             [1, 1, 8, 8]              2\n",
       "        ReLU: 3-3                    [1, 1, 8, 8]              --\n",
       "    Sequential: 2-2                   [1, 1, 8, 8]              --\n",
       "        ConvTranspose2d: 3-4         [1, 1, 8, 8]              9\n",
       "        BatchNorm2d: 3-5             [1, 1, 8, 8]              2\n",
       "Sequential: 1-2                        [1, 1, 8, 8]              --\n",
       "    Sequential: 2-3                   [1, 1, 8, 8]              --\n",
       "        ConvTranspose2d: 3-6         [1, 1, 8, 8]              3\n",
       "        BatchNorm2d: 3-7             [1, 1, 8, 8]              2\n",
       "ReLU: 1-3                              [1, 1, 8, 8]              --\n",
       "==========================================================================================\n",
       "Total params: 45\n",
       "Trainable params: 45\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2= TResBlock(1,1,3)(img)\n",
    "print(img2.shape)\n",
    "torchinfo.summary(TResBlock(1,3,1,transpose=True),img2.shape)\n",
    "# TResBlock(1,3,1)(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2c9e2e1d-0f16-45bd-8bf9-b12b085a21af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 8, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "TResBlock                                --                        --\n",
       "Sequential: 1-1                        [1, 3, 4, 4]              --\n",
       "    Sequential: 2-1                   [1, 3, 4, 4]              --\n",
       "        Conv2d: 3-1                  [1, 3, 4, 4]              27\n",
       "        BatchNorm2d: 3-2             [1, 3, 4, 4]              6\n",
       "        ReLU: 3-3                    [1, 3, 4, 4]              --\n",
       "    Sequential: 2-2                   [1, 3, 4, 4]              --\n",
       "        Conv2d: 3-4                  [1, 3, 4, 4]              81\n",
       "        BatchNorm2d: 3-5             [1, 3, 4, 4]              6\n",
       "Sequential: 1-2                        [1, 3, 4, 4]              --\n",
       "    AvgPool2d: 2-3                    [1, 1, 4, 4]              --\n",
       "    Sequential: 2-4                   [1, 3, 4, 4]              --\n",
       "        Conv2d: 3-6                  [1, 3, 4, 4]              3\n",
       "        BatchNorm2d: 3-7             [1, 3, 4, 4]              6\n",
       "ReLU: 1-3                              [1, 3, 4, 4]              --\n",
       "==========================================================================================\n",
       "Total params: 129\n",
       "Trainable params: 129\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(img.shape)\n",
    "torchinfo.summary(TResBlock(1,1,3,stride=2),img.shape)\n",
    "# TResBlock(1,1,3,stride=2)(img)\n",
    "# rb= TResBlock(1,1,3,stride=2)\n",
    "# rb.convpath(img).shape\n",
    "# rb.idpath(img).shape\n",
    "# rb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "abf1760a-8788-4e5e-9bb4-4d985faf4a74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "TResBlock                                --                        --\n",
       "Sequential: 1-1                        [1, 1, 8, 8]              --\n",
       "    Sequential: 2-1                   [1, 1, 8, 8]              --\n",
       "        ConvTranspose2d: 3-1         [1, 1, 8, 8]              27\n",
       "        BatchNorm2d: 3-2             [1, 1, 8, 8]              2\n",
       "        ReLU: 3-3                    [1, 1, 8, 8]              --\n",
       "    Sequential: 2-2                   [1, 1, 8, 8]              --\n",
       "        ConvTranspose2d: 3-4         [1, 1, 8, 8]              9\n",
       "        BatchNorm2d: 3-5             [1, 1, 8, 8]              2\n",
       "Sequential: 1-2                        [1, 1, 8, 8]              --\n",
       "    Sequential: 2-3                   [1, 1, 4, 4]              --\n",
       "        ConvTranspose2d: 3-6         [1, 1, 4, 4]              3\n",
       "        BatchNorm2d: 3-7             [1, 1, 4, 4]              2\n",
       "    Upsample: 2-4                     [1, 1, 8, 8]              --\n",
       "ReLU: 1-3                              [1, 1, 8, 8]              --\n",
       "==========================================================================================\n",
       "Total params: 45\n",
       "Trainable params: 45\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2= TResBlock(1,1,3,stride=2)(img)\n",
    "print(img2.shape)\n",
    "torchinfo.summary(TResBlock(1,3,1,stride=2,transpose=True),img2.shape)\n",
    "# TResBlock(1,3,1,stride=2,transpose=True)(img2)\n",
    "# rb= TResBlock(1,3,1,stride=2,transpose=True,upsample_first=True)\n",
    "# print(rb.convpath(img2).shape)\n",
    "# print(rb.idpath(img2).shape)\n",
    "# rb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca75a1bd-60a1-4be3-a5f6-e9bf8e23ad23",
   "metadata": {},
   "source": [
    "## ResNet without pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f9d4c58-c1d5-4c09-bc45-77a049b9e4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ay_torch import TResBlock, TResNet, TNoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88729523-b2a2-43f2-a24e-37617f1a98fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.6807, 0.6319, 0.1488, 0.2314, 0.1645, 0.2275, 0.8301, 0.4215],\n",
       "          [0.8867, 0.2966, 0.9344, 0.6837, 0.9192, 0.1543, 0.9079, 0.7589],\n",
       "          [0.8372, 0.8294, 0.2528, 0.7335, 0.8887, 0.3479, 0.5266, 0.9375],\n",
       "          [0.7423, 0.2302, 0.8697, 0.0619, 0.1730, 0.6311, 0.1207, 0.5635],\n",
       "          [0.4931, 0.7887, 0.2703, 0.6939, 0.4062, 0.9014, 0.7710, 0.3900],\n",
       "          [0.5141, 0.9686, 0.1900, 0.2002, 0.1720, 0.5338, 0.1929, 0.7724],\n",
       "          [0.9152, 0.2015, 0.0836, 0.3036, 0.2042, 0.3879, 0.0426, 0.1872],\n",
       "          [0.9524, 0.5482, 0.6289, 0.8618, 0.2832, 0.5301, 0.9718, 0.6986]]],\n",
       "\n",
       "\n",
       "        [[[0.4640, 0.2365, 0.9946, 0.7539, 0.0234, 0.3142, 0.6843, 0.0659],\n",
       "          [0.1769, 0.6768, 0.4790, 0.5934, 0.4234, 0.1729, 0.3388, 0.0212],\n",
       "          [0.4978, 0.1483, 0.8279, 0.4131, 0.3294, 0.4945, 0.3556, 0.1566],\n",
       "          [0.6589, 0.4510, 0.2039, 0.9783, 0.6589, 0.1906, 0.8111, 0.5160],\n",
       "          [0.6891, 0.9937, 0.1032, 0.4532, 0.0265, 0.9145, 0.3716, 0.3260],\n",
       "          [0.3979, 0.0926, 0.4076, 0.2745, 0.7731, 0.4823, 0.9309, 0.9753],\n",
       "          [0.7954, 0.9139, 0.7152, 0.3821, 0.3809, 0.7550, 0.2252, 0.4030],\n",
       "          [0.0217, 0.5690, 0.4489, 0.2885, 0.0212, 0.0437, 0.5431, 0.0351]]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img= torch.from_numpy(np.random.uniform(0,1,size=(2,1,8,8))).float()\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f203bf49-c734-4fc2-9e15-2b061f597c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 8, 8])\n",
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "TResNet                                       --                        --\n",
      "Sequential: 1-1                             [2, 32, 8, 8]             --\n",
      "    Conv2d: 2-1                            [2, 32, 8, 8]             288\n",
      "    BatchNorm2d: 2-2                       [2, 32, 8, 8]             64\n",
      "    ReLU: 2-3                              [2, 32, 8, 8]             --\n",
      "Sequential: 1-2                             [2, 32, 4, 4]             --\n",
      "    Conv2d: 2-4                            [2, 32, 4, 4]             9,216\n",
      "    BatchNorm2d: 2-5                       [2, 32, 4, 4]             64\n",
      "    ReLU: 2-6                              [2, 32, 4, 4]             --\n",
      "Sequential: 1-3                             [2, 64, 2, 2]             --\n",
      "    Conv2d: 2-7                            [2, 64, 2, 2]             18,432\n",
      "    BatchNorm2d: 2-8                       [2, 64, 2, 2]             128\n",
      "    ReLU: 2-9                              [2, 64, 2, 2]             --\n",
      "TNoop: 1-4                                  [2, 64, 2, 2]             --\n",
      "Sequential: 1-5                             [2, 64, 2, 2]             --\n",
      "    TResBlock: 2-10                        [2, 64, 2, 2]             --\n",
      "        Sequential: 3-1                   [2, 64, 2, 2]             73,984\n",
      "        Sequential: 3-2                   [2, 64, 2, 2]             --\n",
      "        ReLU: 3-3                         [2, 64, 2, 2]             --\n",
      "    TResBlock: 2-11                        [2, 64, 2, 2]             --\n",
      "        Sequential: 3-4                   [2, 64, 2, 2]             73,984\n",
      "        Sequential: 3-5                   [2, 64, 2, 2]             --\n",
      "        ReLU: 3-6                         [2, 64, 2, 2]             --\n",
      "Sequential: 1-6                             [2, 128, 1, 1]            --\n",
      "    TResBlock: 2-12                        [2, 128, 2, 2]            --\n",
      "        Sequential: 3-7                   [2, 128, 2, 2]            221,696\n",
      "        Sequential: 3-8                   [2, 128, 2, 2]            8,448\n",
      "        ReLU: 3-9                         [2, 128, 2, 2]            --\n",
      "    TResBlock: 2-13                        [2, 128, 1, 1]            --\n",
      "        Sequential: 3-10                  [2, 128, 1, 1]            295,424\n",
      "        Sequential: 3-11                  [2, 128, 1, 1]            --\n",
      "        ReLU: 3-12                        [2, 128, 1, 1]            --\n",
      "Sequential: 1-7                             [2, 256, 1, 1]            --\n",
      "    TResBlock: 2-14                        [2, 256, 1, 1]            --\n",
      "        Sequential: 3-13                  [2, 256, 1, 1]            885,760\n",
      "        Sequential: 3-14                  [2, 256, 1, 1]            33,280\n",
      "        ReLU: 3-15                        [2, 256, 1, 1]            --\n",
      "    TResBlock: 2-15                        [2, 256, 1, 1]            --\n",
      "        Sequential: 3-16                  [2, 256, 1, 1]            1,180,672\n",
      "        Sequential: 3-17                  [2, 256, 1, 1]            --\n",
      "        ReLU: 3-18                        [2, 256, 1, 1]            --\n",
      "Sequential: 1-8                             [2, 512, 1, 1]            --\n",
      "    TResBlock: 2-16                        [2, 512, 1, 1]            --\n",
      "        Sequential: 3-19                  [2, 512, 1, 1]            3,540,992\n",
      "        Sequential: 3-20                  [2, 512, 1, 1]            132,096\n",
      "        ReLU: 3-21                        [2, 512, 1, 1]            --\n",
      "    TResBlock: 2-17                        [2, 512, 1, 1]            --\n",
      "        Sequential: 3-22                  [2, 512, 1, 1]            4,720,640\n",
      "        Sequential: 3-23                  [2, 512, 1, 1]            --\n",
      "        ReLU: 3-24                        [2, 512, 1, 1]            --\n",
      "AdaptiveAvgPool2d: 1-9                      [2, 512, 1, 1]            --\n",
      "Flatten: 1-10                               [2, 512]                  --\n",
      "Dropout: 1-11                               [2, 512]                  --\n",
      "Linear: 1-12                                [2, 1]                    513\n",
      "===============================================================================================\n",
      "Total params: 11,195,681\n",
      "Trainable params: 11,195,681\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 25.08\n",
      "===============================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.30\n",
      "Params size (MB): 44.78\n",
      "Estimated Total Size (MB): 45.09\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)\n",
    "# TResNet(TResBlock,1,[2,2,2,2],in_channels=1,out_channels=1)(img)\n",
    "print(torchinfo.summary(TResNet(TResBlock,1,[2,2,2,2],in_channels=1,out_channels=1,rnpool=TNoop),img.shape))\n",
    "# print(torchinfo.summary(TResBlock(1,1,3,stride=2,pool=TNoop),img.shape))\n",
    "# TResBlock(1,1,3)(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8dae63-b518-40bf-8f25-65f3e136760b",
   "metadata": {},
   "source": [
    "# Torch functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5356eb25-66bd-4dc3-9f08-dd7c5993c92e",
   "metadata": {},
   "source": [
    "## Softmax and clamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "026a0a2f-9cf4-4681-b651-a0149c27fe55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1590, -0.4883,  0.0481, -0.2388, -0.4310],\n",
       "          [-0.2900,  0.2253, -0.2798,  0.2368,  0.6311],\n",
       "          [-0.4764,  0.6701,  0.8507,  0.3041,  0.8848],\n",
       "          [ 0.0155, -0.5271, -0.7959,  0.2696,  0.9397],\n",
       "          [ 0.2211,  0.3824, -0.3784,  0.1784,  0.5068]]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img= torch.from_numpy(np.random.uniform(-1,1,size=(1,1,5,5)))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "88691578-1bb1-47d1-b25e-9d9fb26fffc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.5397, 0.3803, 0.5120, 0.4406, 0.3939],\n",
       "          [0.4280, 0.5561, 0.4305, 0.5589, 0.6527],\n",
       "          [0.3831, 0.6615, 0.7007, 0.5754, 0.7078],\n",
       "          [0.5039, 0.3712, 0.3109, 0.5670, 0.7190],\n",
       "          [0.5551, 0.5945, 0.4065, 0.5445, 0.6240]]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0232e813-cbc7-4fe4-8e36-c41f41fa09dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1590, 0.0000, 0.0481, 0.0000, 0.0000],\n",
       "          [0.0000, 0.2253, 0.0000, 0.2368, 0.6311],\n",
       "          [0.0000, 0.6701, 0.8507, 0.3041, 0.8848],\n",
       "          [0.0155, 0.0000, 0.0000, 0.2696, 0.9397],\n",
       "          [0.2211, 0.3824, 0.0000, 0.1784, 0.5068]]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.clamp(img,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240260e9-5421-4d59-8d28-f5bce70196fa",
   "metadata": {},
   "source": [
    "## Loss and reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9929777-a71d-4d5b-92b2-4f31a7dcf1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred= tensor([[ 0.0474, -0.8917,  0.4548,  0.7686,  0.3054]])\n",
      "y_trg= tensor([[-1.1532,  0.4937,  1.0670,  0.5567, -0.9121]])\n",
      "loss(mean)= 1.0526280403137207\n",
      "loss(sum)= 5.2631402015686035\n",
      "loss(none)= tensor([[1.4415, 1.9195, 0.3748, 0.0449, 1.4824]])\n"
     ]
    }
   ],
   "source": [
    "y_pred= torch.randn((5,1))\n",
    "y_trg= torch.randn((5,1))\n",
    "# f_loss= torch.nn.functional.l1_loss\n",
    "f_loss= torch.nn.functional.mse_loss\n",
    "print(f'y_pred= {y_pred.T}')\n",
    "print(f'y_trg= {y_trg.T}')\n",
    "print(f'loss(mean)= {f_loss(y_pred,y_trg,reduction=\"mean\")}')\n",
    "print(f'loss(sum)= {f_loss(y_pred,y_trg,reduction=\"sum\")}')\n",
    "print(f'loss(none)= {f_loss(y_pred,y_trg,reduction=\"none\").T}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93edc2e7-dd50-45b2-8680-afe78b0b6601",
   "metadata": {},
   "source": [
    "### Weighted average loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81b505e5-b6f6-44c7-beea-04bd7449db78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight= tensor([[1., 1., 1., 1., 1.]])\n",
      "weighted_average_loss= 1.0526280403137207\n",
      "weight= tensor([[0.8862, 0.8221, 0.7881, 0.0985, 0.5323]])\n",
      "weighted_average_loss= 1.2612899541854858\n"
     ]
    }
   ],
   "source": [
    "def weighted_average_loss(pred, trg, w):\n",
    "  return torch.sum(w*f_loss(pred,trg,reduction='none'))/torch.sum(w)\n",
    "weight= torch.ones((5,1))\n",
    "print(f'weight= {weight.T}')\n",
    "print(f'weighted_average_loss= {weighted_average_loss(y_pred,y_trg,weight)}')\n",
    "weight= torch.from_numpy(np.random.uniform(0,1,size=(5,1))).float()\n",
    "print(f'weight= {weight.T}')\n",
    "print(f'weighted_average_loss= {weighted_average_loss(y_pred,y_trg,weight)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25daa3e0-b638-4a0f-9297-488dcfa98881",
   "metadata": {},
   "source": [
    "## torch.heaviside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89f52500-ba0f-4b78-ad75-0ced490ebd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x= tensor([0.1000, 0.1000, 1.0000, 1.0000, 0.1000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 1., 0.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= torch.tensor([0.1,0.1,1.0,1.0,0.1])\n",
    "print(f'x= {x}')\n",
    "torch.heaviside(x-0.5,torch.tensor([0.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00747ef9-1d1c-4ffe-8a15-092963426b99",
   "metadata": {},
   "source": [
    "## torch.nn.functional.threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59e25581-4455-4880-8cda-1a6a2937eafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x= tensor([0.1000, 0.1000, 1.0000, 1.0000, 0.1000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 1., 0.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= torch.tensor([0.1,0.1,1.0,1.0,0.1])\n",
    "print(f'x= {x}')\n",
    "torch.nn.functional.threshold(x,0.5,0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9359a486-cb0f-4354-a03c-3b4bbfb0c7c0",
   "metadata": {},
   "source": [
    "# Torch test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a8d0d9-17ca-4b7f-9427-0835cc9edbf6",
   "metadata": {},
   "source": [
    "## Range Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ca1cf63b-8313-4487-96f6-7a89b6fd3ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1= tensor([[ 90., -67.,  79.,  32.,  -1.]])\n",
      "y2= tensor([[ -69.,  -32.,  -50., -224., -183.]])\n",
      "y_trg= tensor([[ 82.,   2.,  71., 158., 138.]])\n"
     ]
    }
   ],
   "source": [
    "y1,y2,y_trg= (torch.round(torch.randn((5,1))*100.) for _ in range(3))\n",
    "print(f'y1= {y1.T}')\n",
    "print(f'y2= {y2.T}')\n",
    "print(f'y_trg= {y_trg.T}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6c14731f-6837-4f26-a216-cdf5a0989e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "berr1= tensor([[False, False, False, False, False]])\n",
      "berr2= tensor([[ True, False,  True, False, False]])\n",
      "berr= tensor([[ True, False,  True, False, False]])\n"
     ]
    }
   ],
   "source": [
    "berr1= torch.logical_and(y1<y_trg, y_trg<y2)\n",
    "berr2= torch.logical_and(y2<y_trg, y_trg<y1)\n",
    "berr= torch.logical_or(berr1, berr2)\n",
    "print(f'berr1= {berr1.T}')\n",
    "print(f'berr2= {berr2.T}')\n",
    "print(f'berr= {berr.T}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "323c6513-7378-490b-aada-279e4e13b32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err1= tensor([])\n",
      "err2= tensor([8., 8.])\n"
     ]
    }
   ],
   "source": [
    "err1= torch.min(torch.abs(y_trg-y1), torch.abs(y_trg-y2))[torch.logical_and(y1<y_trg, y_trg<y2)]\n",
    "err2= torch.min(torch.abs(y_trg-y1), torch.abs(y_trg-y2))[torch.logical_and(y2<y_trg, y_trg<y1)]\n",
    "print(f'err1= {err1.T}')\n",
    "print(f'err2= {err2.T}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a9152832-97dc-4b5a-b9f5-455b4b23fa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "berr= tensor([[False,  True, False,  True,  True]])\n",
      "err= tensor([ 34., 126., 139.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(59.8000)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err1,err2= y_trg-y1, y_trg-y2\n",
    "berr= err1*err2>0\n",
    "err= torch.min(torch.abs(err1[berr]), torch.abs(err2[berr]))\n",
    "print(f'berr= {berr.T}')\n",
    "print(f'err= {err.T}')\n",
    "torch.sum(err)/len(berr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "30ed1901-667c-400c-81b7-ce4b8f14de95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ymin= tensor([[ -69.,  -67.,  -50., -224., -183.]])\n",
      "ymax= tensor([[ 90., -32.,  79.,  32.,  -1.]])\n",
      "err= tensor([[  0.,  34.,   0., 126., 139.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(59.8000)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ymin,ymax= torch.min(y1,y2),torch.max(y1,y2)\n",
    "err= torch.nn.functional.threshold(ymin-y_trg,0.0,0,inplace=True)+torch.nn.functional.threshold(y_trg-ymax,0.0,0,inplace=True)\n",
    "print(f'ymin= {ymin.T}')\n",
    "print(f'ymax= {ymax.T}')\n",
    "print(f'err= {err.T}')\n",
    "torch.mean(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4259a281-2f15-49db-a990-d18ec7c732f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yout_err= tensor([[  0.,  34.,   0., 126., 139.]])\n",
      "y_err= tensor([[159., 103., 129., 508., 460.]])\n",
      "torch.mean(yout_err**2)= 7270.60009765625\n",
      "torch.mean(yout_err**2+y_err**2)= 111709.6015625\n",
      "torch.mean(yout_err**2+0.1*y_err**2)= 17714.5\n",
      "torch.mean(yout_err)= 59.79999923706055\n",
      "torch.mean(yout_err+y_err)= 331.6000061035156\n",
      "torch.mean(yout_err+0.1*y_err)= 86.9800033569336\n"
     ]
    }
   ],
   "source": [
    "ymin,ymax= torch.min(y1,y2),torch.max(y1,y2)\n",
    "yout_err= torch.nn.functional.threshold(ymin-y_trg,0.0,0,inplace=True)+torch.nn.functional.threshold(y_trg-ymax,0.0,0,inplace=True)\n",
    "y_err= torch.abs(y_trg-ymin)+torch.abs(y_trg-ymax)\n",
    "print(f'yout_err= {yout_err.T}')\n",
    "print(f'y_err= {y_err.T}')\n",
    "print(f'torch.mean(yout_err**2)= {torch.mean(yout_err**2)}')\n",
    "print(f'torch.mean(yout_err**2+y_err**2)= {torch.mean(yout_err**2+y_err**2)}')\n",
    "print(f'torch.mean(yout_err**2+0.1*y_err**2)= {torch.mean(yout_err**2+0.1*y_err**2)}')\n",
    "print(f'torch.mean(yout_err)= {torch.mean(yout_err)}')\n",
    "print(f'torch.mean(yout_err+y_err)= {torch.mean(yout_err+y_err)}')\n",
    "print(f'torch.mean(yout_err+0.1*y_err)= {torch.mean(yout_err+0.1*y_err)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
